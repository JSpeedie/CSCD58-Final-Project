# Acknowledgements

This CSCD58 Final Project is comprised of 3 major, distinct contributions.

## 1. Basic FTP Client/Server by users pranav93y and nishant-sachdeva
[https://github.com/pranav93y/Basic-FTP-Client-Server](https://github.com/pranav93y/Basic-FTP-Client-Server)  
It's worth noting that while it served at the FTP implementation that we made our
extensions on (as extensions to FTP was the focus of our project), this code
base was not fully functional. 2 small but important changes had to made
(and which are marked accordingly with comments) so that non-text files
could be both put and retrieved by a client. The original code only supports
text files and starts to break when it encounter non-terminal null bytes.
Instructions on how to use these programs found in this README are partially
modified (just for brevity, and to match other small changes we made (such as
removing an "-out" prefix from retrieved files) from the original instructions.
## 2. The 7-Zip LZMA SDK
[https://7-zip.org/sdk.html](https://7-zip.org/sdk.html)  
The compression algorithm used in our extension to FTP was the LZMA aka the
Lempel-Ziv-Markov chain algorithm, and the C implementation of it that our
project depends on was provided by this public domain SDK. To make it clear,
any .c or .h file that is not `ftpclient.c` or `ftpserver.c` came from this SDK,
and was not touched in anyway by us.
## 3. Us! The CSCD58 students who worked on this project!
## Other Contributors
Several minor contributions came from Wikipedia. Specifically, the `ROTC` definition, 
as well as the `initialize_aes_sbox()` and `g_mul()` functions, all in `aes.c`.


# Motivation, Description, Explanation, Goals

## Motivation

### Why add parallelization?
FTP is traditionally sequential over a single data channel, with the file being
sent from the first byte to the last. We want to take advantage of multiple
data channels and send file segments simultaneously in order to significantly
speed up transfer, especially for large files.

### Why add encryption?
Last year Chrome and Firefox disabled support for FTP over security concerns
(see for instance
[https://chromestatus.com/feature/6246151319715840](https://chromestatus.com/feature/6246151319715840))
since it is entirely unencrypted (it has no security measures at all!) and
prone to a variety of attacks. We wanted to make our own modern file transfer
protocol that is secure!

### Why add compression?
To reduce the demands on the networks by using a high compression ratio
compression algorithm (such as the Lempel–Ziv–Markov chain algorithm (LZMA)
that we used in this project) and reduce the number of bytes the network has to
transport. It's worth noting that this incurs a cost to the server and client
who have to compress/uncompress at the beginning and end of every transfer
(which under most circumstances will increase the time it takes to transfer the
files), but they do so for the benefit of the network.

## Description
This project is a client/server program pair that implements FTP with 3
extensions: Parallelization, encryption, and compression. For this reason,
internally it is referred to as `pec-ftp`.

## Explanation
The way this extends on FTP is as follows:
1. The client issues a GET command to the server to retrieve a file, or the
   server receives a STOR command from the client - either way, one party will
   receive a file and one will send.
2. The sender takes the original file and compresses it into our own file
   format (`.comp`) creating a temp file for the new file to avoid overwriting
   other files (`.comp-XXXXXX` where XXXXXX are random digits generated by
   `mkstemp()`).
3. The sender then takes that `.comp` file and encrypts it and adds the `.enc`
   extension creating a temp file for the new file to avoid overwriting other
   files (`.comp.enc-XXXXXX` where XXXXXX are random digits generated by
   `mkstemp()`).
4. The sender sends this `.comp.enc` file to the receiver, who creates their
   own temp file to receive it (`.comp.enc-XXXXXX`).
5. The receiver then decrypts the file, creating a temp file for the decrypted
   file (`.comp-XXXXXX`, which still has to be uncompressed).
6. The receiver then uncompresses the file, creating the original raw file!

## Goals
To successfully add parallelization, encryption and compression to an existing
FTP library!


# Contributions + Analysis + Discussion

## Julian Speedie (speedie1, 1001712952)
Julian made the small fixes to the original FTP client/server program pair to
get it to work with all types of files, and worked on the compression part of
the project. Most of that work can be found in `comp.c`, `comp.h`, and
the compression related changes made in `do_put()`, `do_get()` of `src/ftpclient.c`
and in `do_retr()`, `do_stor()` of `src/ftpserver.c`, but code involving
the use of temporary files is also a part of that work.

Of note was the work on a custom file format needed for the proper transfer of
files from client to server or vice versa. This format - which is used for files
that end in `.comp` (which hopefully you will never see since they are meant to
be temporary) - takes the form of repeated blocks, each having the structure:
```
8 bytes for a uint64_t representing the length (in bytes) of the compressed data in the data chunk of this block.
1 byte for a char representing whether the data in the data chunk is raw and unchanged (=0) or LZMA compressed (=1).
8 bytes for a uint64_t representing the length (in bytes) of the data when it is uncompressed.
x bytes of data (specified by the first 8 bytes) for the data chunk.
```
This was necessary for 2 reasons. First, the compression algorithm does not
always return a data stream that is smaller than the stream of original data.
In those cases, it's better to send the original data than data that not only
takes more space but must also be uncompressed upon receiving it. Secondly,
it's more efficient to send the size of the uncompressed data chunk (a number
we know from when we compressed the data chunk) and allocate precisely enough
space to uncompress than it is to allocate more than be needed and resizing
later.

The main takeaway I have after implementing compression like this is the
question of whether or not compression should be implemented at the application
layer. For one, maybe we should save the compressed file instead of compressing
with each request so that we don't incur needless repeated compression, a
process that is costly in terms of time and cpu usage. Problems arise there
however as the server then has to have some way to be sure that its collection
of associated compressed files are indeed compressed versions of the original
files. What if someone deletes the original file, or changes it, when will the
compressed version be updated? Solutions exist to all these potential problems,
but we could not make such a system due to time limitations. The second problem
with implementing compression at the application layer is that it costs the
sender a lot of time and cpu usage (as well as the receiver who has to
uncompress at the end) and doesn't save much (comparatively) for the network.
Big files that can benefit a lot from compression could easily take many times
longer to compress than they would've taken to send over the network. And
that's not even counting the time it would take to decompress them.


## Dawson Brown (browndaw, 1005392932)
Dawson worked on the encryption portion of the project. Work can be found in
the files `enc.c`, `enc.h`, `aes.c`, and `aes.h`. Specifically, `aes.c`
includes an implementation of Rjindael encryption (see
https://en.wikipedia.org/wiki/Advanced_Encryption_Standard) with a 128-bit key,
using ECB mode. `enc.c` includes methods for encrypting and decrypting files
using the aes code, as well as an implementation of the square and multiply
algorithm for calculating the power of large values mod n.

When performing the put or get operations, the client and server first
intialize a key exchange using the diffie-hellman algorithm. This takes place
in 4 stages, each stage exchanging a random 32-bit integer, resulting in four
32-bit integers which are passed into the encryption and decryption functions
as a key. A unique key is generated for every file exchange. This is done using
a hard-coded prime 2^32 - 99, and a hard-coded generator 5.

Once the keys are exchanged, and after the file is compressed, the sender
encrypts the file using the previously mentioned code and saves it into a temp
file. The temp file is transmitted to the receiver, then deleted. On the
receiving end, the entire transmission is saved into a temp file, decrypted
into a second temp file, then decompressed to produce the final result. Temp
files were used to avoid concerns with reading from sockets - namely, since it
is not guarenteed that the amount of data read is equal to the amount of data
sent, if the data was encrypted during sending, then decrypted on arrival,
there is no guarentee that the received data would be a multiple of the block
size. Attempting to decrypt this would result in undefined behaviour for the
last block, and leave artifacts throughout the file.

To ensure the transmitted file is not a multiple of the block size (16 bytes),
the end of the file is buffered with up to 16 bytes, where the data is equal to
the number of buffer bytes (i.e. if a file were 19 bytes, a 13 byte buffer
would be used where each byte has value 13). If the file is already a multiple
of the block size, it is buffered with 16 bytes regardless. This means the
receiver can remove the buffere data simply by removing a number of characters
equal to the value of the last byte of data.

DISCLAIMER: Since this is a minimal implementation, it carries many security
concerns. First, Electronic Code Book (ECB) mode encrypts each 16 byte block
independently of the others, using the same key. This means patterns in the
data are preserved, and identical blocks will be encrypted identically, making
it very vulnerable to cryptanalysis (For more information, see
https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Electronic_codebook_(ECB)).
For more secure encryption, a different mode (such as Cypher Block Chaining,
which modifies each block based on the previous one) would have to be used.
Additonally, the Diffie-Hellman private keys are generated using the built in C
rand() function seeded with the system time. The built in rand() implementation
produces correlated numbers with a short period, which can lead to
vulnerabilities. Cryptographically secure random number generators are
available, and would be far more secure. Finally, there are many side channel
attacks (see https://en.wikipedia.org/wiki/Side-channel_attack) which this
implementation does not defend against. While the implementation is ultimately
suitable for our needs and does provide a level of encryption, it should not be
considered secure in any production environment.

## Jacky Fong (fongkwan, 991686118)
Jacky worked on the parallelization part of the project. Explored several
different I/O event notification facilities (e.g. POSIX select and poll) and
third party libraries (e.g. libuv and libev) for implementing parallelized file
transfers. Evaluated the different options to determine what works best with
the chosen codebase.

For the parallelization, we opted for a simplistic approach of distributing file chunks
across a set of data connections by cycling through each associated file descriptor.
The aim is to keep much of the FTP control logic the same.

Jacky was also responsible for cleaning up the build process and code, as well as 
preparing the video demo of pec-ftp in action.


# How to run and test

## Compilation
First you will need to compile the project. You can do this by running the
following commands:
```
cd basic-FTP-Client-Server/
cd src/
make
```
This will compile both the `ftpclient` and `ftpserver` binaries placing them in
`basic-FTP-Client-Server/bin/ftpclient/` and
`basic-FTP-Client-Server/bin/ftpserver/`, respectively.

## Running the code
In one terminal, start the server:
```
cd basic-FTP-Client-Server/
cd bin/ftpserver/
./ftpserver <listen-port>
```
For example:
```
./ftpserver 45678
```

In another terminal, start the client:
```
cd basic-FTP-Client-Server/
cd bin/ftpclient/
./ftpclient <server-ip> <server-listen-port>
```
For example: (make sure you run the server first)
```
./ftpclient 127.0.0.1 45678
```
If your ftpclient says its connection was denied, make sure you entered the same
port for both your ftpserver and ftpclient. If you did, try a different port.

You will interface with the server through the client, you cannot run any
commands on the server side, but you will see some output that might be helpful.

### Client Interface Commands

- ls, lists the current directory
- get <filename>, gets the file from server to client. The file obtained will
  have and appended format of “-out” at the end of the original filename.
- put <filename>, puts the files from the client to the server. The file
  transferred to the server will have an appended format of “-out”, similar to
  get.
- quit, exits the client program

## Tests
To test, you want to setup 2 terminals as described in the "Running the code"
section, and also you may need to copy a variety of files into both your
`basic-FTP-Client-Server/bin/ftpserver/` directory (for the client to access)
and into your `basic-FTP-Client-Server/bin/ftpserver/` directory (for the
client to put) (we provide some in the zip that we submitted, but feel free to
test with more). Once you've done that, feel free to begin any of the following
tests:

### 1. Client GET/Server RETR
1. From your `ftpclient` terminal, type `ls` at the `ftpclient` prompt and hit
   enter to see what files the server has.
2. To retrieve a file from the server, type `get <filename>` and wait to
   receive the file.
3. It should appear (byte for byte identical to the original on the server, in
   content and name) in your `basic-FTP-Client-Server/bin/ftpclient` directory!

### 2. Client PUT/Server STOR
1. If you are running the `ftpclient`, press Ctrl+C to kill the process. From
   your `basic-FTP-Client-Server/bin/ftpclient` directory, run the shell
   command `ls` to see what files your client has access to. Then startup the
   client again with the command: `./ftpclient <server-ip>
   <server-listen-port>`
2. From your `ftpclient` terminal, type `ls` at the prompt and hit enter to see
   what files the server has (we don't want to overwrite any of them!)
3. To put a file from the server, type `get <local-filename>` (where
   `<local-filename>` is  one of the filenames printed by the shell command
   `ls` in step 1) and wait to receive the file.
4. It should appear (byte for byte identical to the original on the server, in
   content and name) in your `basic-FTP-Client-Server/bin/ftpclient` directory!

### 3. Seeing the .enc and .comp files
1. Press Ctrl+C in both your `ftpclient` terminal and your `ftpserver` terminal
   if they are running.
1. Edit `src/pec-ftp.h` and change `KEEP_TEMP_ENC_FILES` to `1` and
   `KEEP_TEMP_COMP_FILES` to `1` as well.
2. Now compile the project again (`cd src` followed by `make`), and start
   `ftpserver` in one terminal and `ftpclient` in another as explained
   in the "Running the code" above.
3. Now when you PUT or GET (from the `ftpclient` prompt:`put <filename>` or
   `get <filename>, respectively) a file, the temporary .comp-XXXXXX and
   .comp.enc-XXXXXX files on both the server and client won't be cleaned up so
   you can see them!

### 4. Seeing packet activity on Wireshark
1. Open up wireshark and select "Loopback: lo" as the interface you want to
   capture on
2. In the filter bar, type "tcp"
3. From your ftpclient terminal (assuming you are running an `ftpserver` in one
   terminal and have a connected `ftpclient` in another), type `ls` at the
   `ftpclient` prompt and hit enter.
4. You should see a sudden burst of about 20-30 packets that represent that
   request and its response by the server.
5. Similarly, at the `ftpclient` prompt we can request a file from the server
   with `get <filename>` (make sure you have put a file for testing in your
   `bin/ftpserver/` directory!). If we look at Wireshark, we should first see a
   20-30 packet burst from the original request, followed by a brief pause as
   the server compresses the requested file, then encrypts it. Following that
   pause, we should see many (depends on the filesize) packets being sent (this
   is the file being transferred over the network), then another pause as the
   receiver decrypts and then uncompresses the file at which point we see one
   last tiny set of packets which are the receiver telling the sender they
   received the file successfully.


*NOTE: The server program will keep running even after a client has been
disconnected, waiting for future connections*

*NOTE: The provided client and server utilities can only access files within
the directories containing the executables, ls however, can list the contents
of directories contained within.*


![Imgur](https://imgur.com/oyjYZ36.gif)
